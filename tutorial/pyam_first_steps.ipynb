{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostics, analysis and visualization tools <br /> for Integrated Assessment timeseries data\n",
    "\n",
    "<img style=\"float: right; height: 100px; margin-top: 10px;\" src=\"_static/IIASA_logo.png\">\n",
    "<img style=\"float: right; height: 80px;\" src=\"_static/IAMC_logo.jpg\">\n",
    "\n",
    "## First steps with the ``pyam_analysis`` package\n",
    "\n",
    "The ``pyam-analysis`` package provides a range of diagnostic tools and functions  \n",
    "for analyzing and working with IAMC-style timeseries data. \n",
    "\n",
    "The package can be used with data that follows the data template convention \n",
    "of the [Integrated Assessment Modeling Consortium](http://www.globalchange.umd.edu/iamc/) (IAMC).\n",
    "An illustrative example is shown below;\n",
    "see [data.ene.iiasa.ac.at/database](http://data.ene.iiasa.ac.at/database/) for more information.\n",
    "\n",
    "\n",
    "| **Model**           | **Scenario**  | **Region** | **Variable**   | **Unit** | **2005** | **2010** | **2015** |\n",
    "|---------------------|---------------|------------|----------------|----------|----------|----------|----------|\n",
    "| MESSAGE V.4         | AMPERE3-Base  | World      | Primary Energy | EJ/y     | 454.5    |\t479.6    | ...      |\n",
    "| ...                 | ...           | ...        | ...            | ...      | ...      | ...      | ...      |\n",
    "\n",
    "This notebook illustrates some basic functionality of the ``pyam-analsysis`` package\n",
    "and the ``IamDataFrame`` class:\n",
    "\n",
    "0. Importing timeseries data from a csv file.\n",
    "0. Listing models, scenarios and variables included in the data.\n",
    "0. Display of timeseries data as dataframe and visualization using simple plotting functions.\n",
    "0. Evaluating the model data and executing a range of diagnostic checks to identify data outliers.\n",
    "0. Categorization of scenarios according to timeseries data.\n",
    "0. Exporting data to Excel\n",
    "\n",
    "\n",
    "## Tutorial data\n",
    "\n",
    "The timeseries data used in this tutorial is a partial snapshot of the scenario database \n",
    "compiled for the IPCC's Fifth Assessment Report (AR5):\n",
    "\n",
    "> Krey V., O. Masera, G. Blanford, T. Bruckner, R. Cooke, K. Fisher-Vanden, H. Haberl, E. Hertwich, E. Kriegler, D. Mueller, S. Paltsev, L. Price, S. Schlömer, D. Ürge-Vorsatz, D. van Vuuren, and T. Zwickel, 2014: *Annex II: Metrics & Methodology*.   \n",
    "> In: *Climate Change 2014: Mitigation of Climate Change. Contribution of Working Group III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change* [Edenhofer, O., R. Pichs-Madruga, Y. Sokona, E. Farahani, S. Kadner, K. Seyboth, A. Adler, I. Baum, S. Brunner, P. Eickemeier, B. Kriemann, J. Savolainen, S. Schlömer, C. von Stechow, T. Zwickel and J.C. Minx (eds.)]. Cambridge University Press, Cambridge, United Kingdom and New York, NY, USA. [Link](https://www.ipcc.ch/report/ar5/wg3/)\n",
    "\n",
    "The complete database is publicly available at [tntcat.iiasa.ac.at/AR5DB/](https://tntcat.iiasa.ac.at/AR5DB/).\n",
    "\n",
    "<img style=\"float: right; height: 100px;\" src=\"_static/AMPERE-Logo.png\">\n",
    "<img style=\"float: right; height: 40px; margin-top: 50px; margin-right: 20px;\" src=\"_static/EMF-Logo_v2.1.png\">\n",
    "\n",
    "The data snapshot used for this tutorial consists of selected data from two model intercomparison projects:\n",
    " - Energy Modeling Forum Round 27 \n",
    "   ([**EMF27**](https://emf.stanford.edu/projects/emf-27-global-model-comparison-exercise)),\n",
    "   see the Special Issue in [*Climatic Change* 3-4, 2014](https://link.springer.com/journal/10584/123/3/page/1).\n",
    " - EU FP7 project [**AMPERE**](https://tntcat.iiasa.ac.at/AMPEREDB/), \n",
    "   see the following scientific publications:\n",
    "   > - Riahi, K., et al. (2015). \"Locked into Copenhagen pledges — Implications of short-term emission targets \n",
    "   >   for the cost and feasibility of long-term climate goals.\" \n",
    "   >   *Technological Forecasting and Social Change* 90(Part A): 8-23.  \n",
    "   >   [DOI: 10.1016/j.techfore.2013.09.016](https://doi.org/10.1016/j.techfore.2013.09.016)\n",
    "   > - Kriegler, E., et al. (2015). \"Making or breaking climate targets: The AMPERE study on \n",
    "   >   staged accession scenarios for climate policy.\"\n",
    "   >   *Technological Forecasting and Social Change* 90(Part A): 24-44.  \n",
    "   >   [DOI: 10.1016/j.techfore.2013.09.021](https://doi.org/10.1016/j.techfore.2013.09.021)\n",
    "\n",
    "<div style=\"text-align: center; padding: 10px; border: 2px solid red; width: 700px\">\n",
    "*The data used in this tutorial is ONLY a partial snapshot of the IPCC AR5 scenario database!*  \n",
    "*This tutorial is only intended for an illustration of the ``pyam-analysis`` package.*\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import package and load data from the AR5 tutorial csv snapshot file\n",
    "\n",
    "First, we import the snapshot timeseries data from the file ``tutorial_AR5_data.csv`` in the ``tutorial`` folder.\n",
    "\n",
    "As a first step, we show lists of all models, scenarios, regions, and variables (with units) included in the snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyam_analysis as iam\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = iam.IamDataFrame(data='tutorial_AR5_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['model'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['model', 'scenario']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['variable', 'unit']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on data filtering\n",
    "Most functions of the ``IamDataFrame`` class take an (optional) argument ``filters``,\n",
    "i.e., a dictionary of filter criteria.\n",
    "\n",
    "### Filtering by model names, scenarios and regions\n",
    "\n",
    "The feature for filtering by **model, scenario or region** is implemented\n",
    "using [regular expressions](https://docs.python.org/3.6/library/re.html) (regex, re)\n",
    "and the _re.match()_ function.\n",
    "This implies that the filtering is done from the beginning of the text string.\n",
    "> Applying the filter ``'model': 'MESSAGE'`` to the function ``scenarios()`` \n",
    "  will return all MESSAGE V.4 scenarios included in the snapshot.  \n",
    "> Filtering for _ESSAGE_ will return an empty set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter({'model': 'MESSAGE'})['scenario'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter({'model': 'ESSAGE'})['scenario'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by variables and hierarchy levels\n",
    "\n",
    "Filtering for **variable** strings using regex\n",
    "is problematic due to the frequent use of the ``\"|\"`` character in the IAMC template\n",
    "to specify a hierarchical.\n",
    "Therefore, this package implements a pseudo-regex syntax, \n",
    "where ``|`` is escaped, ``*`` is used as a wildcard\n",
    "and exact matching at the end of the string is enforced.\n",
    "(in regex lingo, ``*`` is replaced by ``.*`` and ``$`` is appended to the filter string).\n",
    "> Filtering for _Primary Energy_ will return only exactly those data.  \n",
    "> Filtering for _Primary Energy|*_ will return all sub-categories of \n",
    "> primary-energy level (and only the sub-categories).\n",
    "\n",
    "In additon, IAM variables can be filtered by the **level**,\n",
    "i.e., the \"depth\" of the variable in a hierarchical reading of the string separated by `\"|\"`.\n",
    "That is, the variable _Primary Energy_ has level 0, while _Primary Energy|Coal_ has level 1.\n",
    "Filtering by both **variables** and **level** will search for the hierarchical depth \n",
    "_following the <variable> string_, so filter arguments _Primary Energy|*_ and _level = 0_\n",
    "will return all variables immediately below _Primary Energy_.\n",
    "Filtering by **level** only will return all variables up to that depth.\n",
    "\n",
    "To illustrate the functionality of the filters, we first show all sub-categories of the ``Emissions`` variable.  \n",
    "Then, we reduce variables to only two hierarchical levels below ``\"Emissions|\"``; the list returned by the function call will not include ``Emissions|CO2|Fossil Fuels and Industry|Energy Supply|Electricity``, because this variable is three hierarchical levels below ``\"Emissions|\"``.\n",
    "\n",
    "The third example shows how to filter only by hierarchical level. The function returns all variables that are at the top hierarchical level (i.e., ``Primary Energy``) and those at the first sub-category level.\n",
    "Keep in mind that there are no variables ``Emissions`` or ``Price`` (no top level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(filters={'variable': 'Emissions|*'})['variable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(filters={'variable': 'Emissions|*', 'level': 2})['variable'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(filters={'level': 1})['variable'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by year\n",
    "\n",
    "Filtering for **years** can be done by integer number, a list of integers, or the Python class ``range``.  \n",
    "Note that the last year of a range is not included, so ``range(2010,2015)``\n",
    "is interpreted as ``[2010, 2011, 2012, 2013, 2014]``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting help\n",
    "\n",
    "When in doubt, you can look at the help for any function by appending it with a ``?``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.filter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying timeseries data and plotting figures\n",
    "\n",
    "As a next step, we want to view a selection of the data in the tutorial snapshot using the IAMC standard.\n",
    "The filtered data can exported as a csv file by appending `.to_csv('selected_data.csv')` to the next command.\n",
    "\n",
    "For displaying data in a different format, the class ``IamDataFrame`` has a wrapper of the ``pandas.DataFrame.pivot_table()`` function. It allows to flexibly specify the columns and rows.\n",
    "The function automatically aggregates by summation or counting (specified by the parameter `aggfunc`) \n",
    "over all timeseries data identifiers ('model', 'scenario', 'variable', 'region', 'unit', 'year')\n",
    "which are not used as `index` or `columns`.\n",
    "\n",
    "In the example below, the filter of the timeseries data is set for all subcategories of 'Primary Energy', \n",
    "which are then summed up in the displayed table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .filter(filters={'scenario': 'AMPERE3-450', 'variable': 'Primary Energy|Coal', 'region': 'World'})\n",
    " .timeseries()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .filter({'variable': 'Primary Energy', 'region': 'World'})\n",
    " .pivot_table(index=['year'], columns=['scenario'], values='value', aggfunc='sum')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are familiar with the `python` package `pandas`, you can treat the IamDataFrame similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of timeseries\n",
    "\n",
    "Please see the `plotting.ipynb` notebook for a full tutorial on plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation and diagnostic assessment of timeseries data\n",
    "\n",
    "When analyzing scenario results, it is often useful to check whether certain timeseries exist or the values are within a specific range. For example, it may make sense to ensure that reported data for historical periods are close to established reference data.\n",
    "\n",
    "The following section provides three illustrations:\n",
    "1. Check whether a timeseries `'Primary Energy'` exists in each scenario (in at least one year).\n",
    "2. Check for every scenario whether the value for `'Primary Energy'` at the global level exceeds 515 EJ/y \n",
    "   in the reference year 2010\n",
    "   (the value must satisfy an upper bound of 515 EJ/y in this notation).\n",
    "3. Check for every scenario whether the value for `'Primary Energy|Coal'` exceeds 400 EJ/y in mid-century.\n",
    "\n",
    "The `validate()` function takes a `filters` dictionary to perform the checks on a selection of models/scenarios\n",
    "similar to the functions introduced above.  \n",
    "The ``criteria`` argument can specify a valid range by an upper and lower bound (``up``, ``lo``) for a variable and a subset of years to which the validation is applied - all scenarios with a value in at least one year outside that range are considered to *not satisfy* the validation.\n",
    "\n",
    "By setting the argument ``exclude=True``, all scenarios failing the validation will be categorized as ``exclude``.\n",
    "These scenarios will not be shown by default in any subsequent data tables or plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.validate(criteria={'Primary Energy': {'up': 515, 'year': 2010}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .filter(filters={'region': 'World'})\n",
    " .validate(criteria={'Primary Energy|Coal': {'up': 400, 'year': 2050}})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam.validate(df, \n",
    "             filters={'region': 'World'}, \n",
    "             criteria={'Primary Energy|Coal': {'up': 400, 'year': 2050}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorization of scenarios by timeseries characteristics\n",
    "\n",
    "It is often useful to apply categorization to classes of scenarios according to specific characteristics of the timeseries data.\n",
    "\n",
    "In the following example, we use the temperature change assessment by MAGICC 6 to group scenarios by the median global warming by the end of the century (year 2100).\n",
    "\n",
    "We proceed in the following steps:\n",
    "\n",
    "0. Plot the timeseries data of the variable that we want to use. \n",
    "   This provides some insights on useful thresholds for the categorization.\n",
    "0. Use the function ``category()`` to apply a categorization (and colour code for later use) \n",
    "   to all scenarios that satisfy a number of specific criteria.\n",
    "0. Use the categorization of scenarios for analysis of other timeseries data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter({'variable': 'Temperature*'}).line_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the categorization feature of the ``pyam-analysis`` package. \n",
    "By default, each model/scenario is assigned as ``\"uncategorized\"``.\n",
    "\n",
    "The next function resets all scenarios back to ``\"uncategorized\"``. This may be helpful in this tutorial if you are going back and forth between cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize(\n",
    "    'Temperature', 'Below 1.6C',\n",
    "    criteria={'Temperature|Global Mean|MAGICC6|MED': {'up': 1.6, 'year': 2100}},\n",
    "    color='cornflowerblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize(\n",
    "    'Temperature', 'Below 2.0C',\n",
    "    criteria={'Temperature|Global Mean|MAGICC6|MED': {'up': 2.0, 'lo': 1.6, 'year': 2100}},\n",
    "    color='forestgreen'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize(\n",
    "    'Temperature', 'Below 2.5C',\n",
    "    criteria={'Temperature|Global Mean|MAGICC6|MED': {'up': 2.5, 'lo': 2.0, 'year': 2100}},\n",
    "    color='gold'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize(\n",
    "    'Temperature', 'Below 3.5C',\n",
    "     criteria={'Temperature|Global Mean|MAGICC6|MED': {'up': 3.5, 'lo': 2.5, 'year': 2100}},\n",
    "     color='firebrick'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize(\n",
    "    'Temperature', 'Above 3.5C',\n",
    "    criteria={'Temperature|Global Mean|MAGICC6|MED': {'lo': 3.5, 'year': 2100}},\n",
    "    color='magenta'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.categorize('Temperature', 'No Data', criteria='uncategorized', color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models included in the snapshot have not been assessed by MAGICC6 regarding their long-term climate and warming impact. Therefore, the timeseries ``'Temperature|Global Mean|MAGICC6|MED'`` does not exist, and they have not been categorized.\n",
    "\n",
    "Below, we display all scenarios that are uncategorized at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Temperature'].head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we again display the median global temperature increase for all scenarios, but we use the colouring by category to illustrate the common charateristics across scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter({'variable': 'Temperature*'}).line_plot(color='Temperature', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step, we display the aggregate CO2 emissions by category. This allows to highlight alternative pathways within the same category. \n",
    "\n",
    "In this step, we also export this figure as a png using the option ``save``. The figure will be saved in the tutorials folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "(df\n",
    " .filter({'variable': 'Emissions|CO2', 'region': 'World'})\n",
    " .line_plot(ax=ax, color='Temperature', legend=True)\n",
    ")\n",
    "fig.savefig('co2_emissions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data to Excel\n",
    "\n",
    "The IamDataFrame can be directly exported to Excel in the standard IAMC format.\n",
    "This feature is based on [pandas.DataFrame.to_excel()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_excel.html) and can use any keyword arguments of that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('tutorial_export.xlsx')\n",
    "df.export_metadata('tutorial_metadata.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
