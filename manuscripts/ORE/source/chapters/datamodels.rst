Data models and formats used by the energy & climate modelling communities
==========================================================================

When researchers in the domain of energy modelling and climate science hear the term
"model", they usually think of numerical tools to compute results from given inputs.
This section is about a different type of model.

A "data model" is an abstract description of the structure of information.
It can refer to timeseries data, static characteristics of technologies or resources,
or any other numerical information. In its essence, a table with clear rules
on the kind of values in each column is already a data model.

Numerous concepts are in use in the domain of energy systems modelling and
climate science to store reference data, facilitate exchange of data between models,
or make results available to other users.
This section describes commonly used data models and related formats in the
integrated-assessment community as well as the domain of energy systems,
macro-energy, and climate modelling.

The IAMC format
---------------

A decade ago, the *Integrated Assessment Modeling Consortium*
(`IAMC <https://www.iamconsortium.org>`_)
established a simple tabular template to exchange yearly timeseries data
related to energy systems modelling, land-use (change), demand sectors,
and economic indicators in the context of climate change mitigation scenarios.
Previous high-level use cases include reports by the *Intergovernmental Panel on
Climate Change* (IPCC, :cite:`Huppmann:2018:NCC`) and model comparison exercises
within the *Energy Modeling Forum* (`EMF <https://emf.stanford.edu>`_)
hosted by Stanford University.

The tabular format consists of the columns *model*, *scenario*, *region*, *variable*
and *unit* as well as one column per year.
The IAMC also introduced conventions on the structure of the identifiers.
Most importantly, the *variable* column describes the type of information represented
in the specific timeseries. It implements a "semi-hierarchical" structure
using the :code:`|` character (*pipe*, not l or i) to indicate the *depth*.
Variable names (should) follow a structure
like *Category|Subcategory|Specification*.

Semi-hierarchical means that a hierarchy can be imposed, e.g., a user can specify
that the sum of *Emissions|CO2|Energy* and *Emissions|CO2|Other*
must be equal to *Emissions|CO2* (if there are no other *Emissions|CO2|â€¦* variables).
However, this is not always mandatory: for example, the sum of *Primary Energy|Coal*,
*Primary Energy|Gas* and *Primary Energy|Fossil* should not be equal
to *Primary Energy* because this would double-count fossil fuels.

The openENTRANCE extensions of the IAMC format
----------------------------------------------

The Horizon 2020 project `openENTRANCE <https://openentrance.eu>`_
adapted the IAMC data template and extended
it in two directions to make the format better suited for energy systems modelling.
Specifically, this requires a more detailed representation of subannual data
and a better solution to represent trade flows and similar inter-regional quantities,
i.e., timeseries for data that is defined on the connection between two regions.

To this end, the openENTRANCE project introduced a *subannual* column to the IAMC format
to describe data at a subannual resolution:
the entries of that column can be identifiers like "Summer" or "January", or
timestamps stripped of the "year" component, e.g., "01-01 06:00:00+01:00"
for January 1st, 6 am in the Central European time zone
(the year information remains in the columns of the tabular data.)

The second extension concerns *directional* information,
e.g., trade flows or energy transmission from one region to a neighbouring country.
A :code:`>` sign in the region column can be used to indicate the source and destination
of the timeseries in that row, e.g., *Region A>Region B*.

To facilitate the adoption and usage of these conventions, the openENTRANCE consortium
developed an `installable Python package <https://github.com/openENTRANCE/nomenclature>`_.
This includes the lists of variables, regions and units used in the project to exchange
data between models, and it provides utility functions to validate that a dataset
conforms to the common definitions.

Formats for power sector modelling
----------------------------------

One relatively early and widely used set of open-source tools for electric power
system simulation and optimization is `MATPOWER <https://matpower.org>`_
:cite:`Zimmerman:2011:Matpower`, implemented in MATLAB. Its data model,
the "MATPOWER case format", holds technical and economical parameters of a power
system made of buses, branches, generators and storage units for one particular
snapshot in time.

Subsequent open-source implementations of power system modelling frameworks and tools
like the Python-based `PyPSA <https://pypsa.org>`_ :cite:`Brown:2018:PyPSA`
or `pandapower <http://www.pandapower.org>`_ :cite:`Thurner:2018:Pandapower`
or the Julia-based `PowerSystems.jl <https://github.com/NREL-SIIP/PowerSystems.jl>`_
package each prefer
their own NetCDF, CSV or JSON-based formats to store time-series data,
but most of them include importers for the MATPOWER case format
to easily use the suite of test networks available in that format.
The industry standards CIM (Common Information Format) or PSS/E's "RAW" formats have
found less adoption in the scientific community :cite:`McMorran:2004:CIM`.

Data formats and standards in the climate science community
-----------------------------------------------------------

Within the climate science community, a widespread and well-known data model is that of 
the Coupled Model Intercomparison Project (CMIP, :cite:`Taylor:2012:CMIP5,Erying:2016:CMIP6`).
The data model is designed to handle the enormous CMIP data volumes 
(approximately 18PB, :cite:`Balaji:2018:CMIPInfra`)
generated with participation from dozens of modelling teams
and to ensure consistency across many sub-disciplines of earth sciences and experimental setups.
It has traditionally revolved around the netCDF format and the
`CF metadata convention <https://cfconventions.org/latest.html>`_,
a self-describing binary format designed for array-oriented scientific data 
:cite:`Unidata:2020:netCDF` commonly used for earth sciences data.
The data is organised according to a regularised data reference syntax 
:cite:`Balaji:2018:CMIPInfra`, which splits the data into smaller pieces that can be 
reasonably handled by climate science: the dimensions include the experiment performed,
the model that performed the experiment, the experiment realisation
(not all realisations are the same because the models include chaotic dynamics)
and the version of the output.

One major challenge is often simply accessing the data, for which substantial
computation is normally required. Increasingly, scientists are moving their analysis workflows
to high-performance cloud computing platforms.
This allows to host up-to-date data and supports containerized environments such as
`Pangeo <https://pangeo.io>`_ and `Google Earth Engine <https://earthengine.google.com>`_.

A number of tools have been developed over the years to work specifically with climate data:
`NCL <https://www.ncl.ucar.edu>`_ and `CDO <https://code.mpimet.mpg.de/projects/cdo>`_
:cite:`Schulzweida:2019:CDO` are the most popular command line options.
More recently, the popularity of Python and its ease of working with large multi-dimensional
arrays in `xarray <http://xarray.pydata.org/>`_ :cite:`Hoyer:2017:xarray`
and `Dask <https://docs.dask.org>`_
has led to a growing geosciences ecosystem in that programming language.
This includes climate-specific packages such as
`Iris <https://scitools-iris.readthedocs.io>`_ :cite:`MetOffice:2019:Iris` and
the `ESMValTool <https://www.esmvaltool.org>`_ :cite:`Righi:2020:ESMValTool`,
which builds on Iris in an effort to create
reproducible climate-data analysis workflows whilst also allowing researchers to build 
on each other's data processing efforts, particularly related to parallelisation and 
lazy data handling.
It should be noted that the ESMValTool supports programming languages other than Python,
with the aim of being as open as possible.

Bridging the gap between integrated assessment and climate science
------------------------------------------------------------------

Beyond the CMIP archive, there are a myriad of other data formats and conventions
within the climate literature.
Of these, the most relevant to the integrated-assessment community is
`scmdata <https://github.com/openscm/scmdata>`_ :cite:`Nicholls:2021:scmdata`.
Being built with the IAMC data format (see above) in mind, scmdata uses completely 
interoperable conventions and an identical data format, most notably in the structure 
of the *variable* column.
The close link between scmdata and pyam facilitates the integration between 
integrated-assessment models and reduced complexity climate models.
This linkage is already widely used in projects involving IAMC member institutions and 
the assessment by Working Group 3 of the IPCC.
To extract data from the CMIP archive into the scmdata format,
the package `netCDF-SCM <https://gitlab.com/netcdf-scm/netcdf-scm>`_ was developed
:cite:`Nicholls:2021:CMIPdata`.

The pyam package was initiated based on the IAMC format and the work done to foster the
link between the integrated-assessment community and the climate sciences.
The following section describes the design principles of the package and
the generalized data model for which it can be applied.
