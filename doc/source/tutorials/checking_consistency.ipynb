{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking consistency of a scenario ensemble\n",
    "\n",
    "It has happened ocassionally that the reported data is not internally consistent. Here we show how to make the most of **pyam** to check that a scenario ensemble is complete and that timeseries data \"add up\" across regions and along the variable tree (i.e., that the sum of values of the subcategories such as `Primary Energy|*` are identical to the values of the category `Primary Energy`).\n",
    "\n",
    "We apply these tools to the sample AR5 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "import pyam\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the tutorial data, it contains only a fraction of the AR5 data so is not internally consistent and is hence the perfect dataset to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pyam.IamDataFrame(data='tutorial_AR5_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "With the `pyam.IamDataFrame.check_internal_consistency` method, we can check the internal consistency of a database. If this method returns `None`, the database is internally consistent (i.e. the total variables are the sum of the sectoral breakdowns and the regional breakdown \n",
    "\n",
    "In the rest of this tutorial, we give you a chance to better understand this method. We go through what it is actually doing and show you the kind of output you can expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking variables are the sum of their components\n",
    "\n",
    "We are going to use the `check_aggregate` method of `IamDataFrame` to check that the components of a variable sum to its total. This method takes `np.is_close` arguments as keyword arguments, we show our recommended settings here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_isclose_args = {\n",
    "    \"equal_nan\": True,\n",
    "    \"rtol\": 1e-03,\n",
    "    \"atol\": 1e-05,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `check_aggregate` on the `IamDataFrame` allows us to quickly check if a single variable is equal to the sum of its sectoral components (e.g. is `Emissions|CO2` equal to `Emissions|CO2|Transport` plus `Emissions|CO2|Solvents` plus `Emissions|CO2|Energy` etc.). A returned `DataFrame` will show us where the aggregate is not equal to the sum of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.check_aggregate(\n",
    "    \"Emissions|CO2\", \n",
    "    **np_isclose_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are missing most of the sectoral data in this subset of AR5, the total variables are mostly not equal to their components. The data table above shows us which model-scenario-region combinations this is the case for. As a user, we would then have to examine which sectors we have for each of these model-scenario-region combinations in order to determine what is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking multiple variables\n",
    "\n",
    "We can then wrap this altogether to check all or a subset of the variables in an `IamDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in df.filter(level=1).variables():\n",
    "    diff = df.check_aggregate(\n",
    "        variable, \n",
    "        **np_isclose_args\n",
    "    )\n",
    "    # you could then make whatever summary you wanted\n",
    "    # with diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells us where there are issues as well as where it is not possible to actually check sums because no components have been reported. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking that regions sum to aggregate regions\n",
    "\n",
    "Similarly to checking that the sum of a variable's components give the declared total, we can check that summing regions gives the intended total.\n",
    "\n",
    "To do this, we use the `check_aggregate_regions` method of `IamDataFrame`. By default, this method checks that all the regions in the dataframe sum to World. \n",
    "\n",
    "Using `check_aggregate_regions` on the `IamDataFrame` allows us to quickly check if a regional total for a single variable is equal to the sum of its regional contributors. A returned `DataFrame` will show us where the aggregate is not equal to the sum of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.check_aggregate_region(\n",
    "    \"Emissions|CO2\",\n",
    "    **np_isclose_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, as the AR5 snapshot is incomplete, all World sums are not equal to the regions provided.\n",
    "\n",
    "Once again, we can repeat this analysis over all the variables of interest in an `IamDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in df.variables():\n",
    "    diff = df.check_aggregate_region(\n",
    "        variable, \n",
    "        **np_isclose_args\n",
    "    )\n",
    "    # you could then make whatever summary you wanted\n",
    "    # with diff\n",
    "    if diff is not None:\n",
    "        eg = diff\n",
    "\n",
    "eg.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An internally consistent database\n",
    "\n",
    "If we have an internally consistent database, the returned `DataFrame` will always be none. \n",
    "\n",
    "Repeating the same analysis as above can then confirm that all is well with the database as well as give us some insight into which variables do not have regional or sectoral breakdowns reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent_df = pyam.IamDataFrame(data=\"tutorial_check_database.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in consistent_df.filter(level=1).variables():\n",
    "    diff = consistent_df.check_aggregate(\n",
    "        variable, \n",
    "        **np_isclose_args\n",
    "    )\n",
    "    assert diff is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in consistent_df.filter(level=1).variables():\n",
    "    diff = consistent_df.check_aggregate_region(\n",
    "        variable, \n",
    "        **np_isclose_args\n",
    "    )\n",
    "    assert diff is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it altogether\n",
    "\n",
    "Finally, we provide the `check_internal_consistency` method which does all the above for you and returns a dictionary with all of the dataframes which document the errors.\n",
    "\n",
    "Note: at the moment, this method's regional checking is limited to checking that all the regions sum to the World region. We cannot make this more automatic unless we start to store how the regions relate, see [this issue](https://github.com/IAMconsortium/pyam/issues/106). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if all is good, None is returned\n",
    "print(\"Checking consistent data\"); time.sleep(0.5)\n",
    "assert consistent_df.check_internal_consistency() is None\n",
    "\n",
    "# otherwise we get a dict back\n",
    "print(\"Checking AR5 subset\"); time.sleep(0.5)\n",
    "errors = df.check_internal_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint([k for k in errors.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors[\"Emissions|CO2-aggregate\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
